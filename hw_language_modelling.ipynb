{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petrovortex/dls-homework-sem-2/blob/main/hw_language_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\" width=\"400\"></p>\n",
        "\n",
        "# Домашнее задание. Обучение языковой модели с помощью LSTM (10 баллов)"
      ],
      "metadata": {
        "id": "d0ADTojbpfLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Э\n",
        "В этом задании Вам предстоит обучить языковую модель с помощью рекуррентной нейронной сети. В отличие от семинарского занятия, Вам необходимо будет работать с отдельными словами, а не буквами.\n",
        "\n",
        "\n",
        "Установим модуль ```datasets```, чтобы нам проще было работать с данными."
      ],
      "metadata": {
        "id": "ldHSmYY6p_mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "3yvNdv6cp_0P",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:20:14.749154Z",
          "iopub.execute_input": "2025-10-17T09:20:14.749324Z",
          "iopub.status.idle": "2025-10-17T09:20:23.00135Z",
          "shell.execute_reply.started": "2025-10-17T09:20:14.749309Z",
          "shell.execute_reply": "2025-10-17T09:20:23.000574Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорт необходимых библиотек"
      ],
      "metadata": {
        "id": "rh9ZXSeCpng9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "\n",
        "from collections import Counter\n",
        "from typing import List\n",
        "\n",
        "import seaborn\n",
        "seaborn.set(palette='summer')"
      ],
      "metadata": {
        "id": "XOJi16bLpd_O",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:20:23.002964Z",
          "iopub.execute_input": "2025-10-17T09:20:23.003209Z",
          "iopub.status.idle": "2025-10-17T09:20:30.259786Z",
          "shell.execute_reply.started": "2025-10-17T09:20:23.003188Z",
          "shell.execute_reply": "2025-10-17T09:20:30.259008Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "91JuM0SQvXud",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:20:30.260528Z",
          "iopub.execute_input": "2025-10-17T09:20:30.260927Z",
          "iopub.status.idle": "2025-10-17T09:20:30.451587Z",
          "shell.execute_reply.started": "2025-10-17T09:20:30.260902Z",
          "shell.execute_reply": "2025-10-17T09:20:30.450977Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "adJC8ShFq9HM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:20:30.452232Z",
          "iopub.execute_input": "2025-10-17T09:20:30.452478Z",
          "iopub.status.idle": "2025-10-17T09:20:30.545179Z",
          "shell.execute_reply.started": "2025-10-17T09:20:30.45246Z",
          "shell.execute_reply": "2025-10-17T09:20:30.544467Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных\n",
        "\n",
        "Воспользуемся датасетом imdb. В нем хранятся отзывы о фильмах с сайта imdb. Загрузим данные с помощью функции ```load_dataset```"
      ],
      "metadata": {
        "id": "pwsfS1ENq5ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('imdb')"
      ],
      "metadata": {
        "id": "qHLNWOfJqSfc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:20:30.54707Z",
          "iopub.execute_input": "2025-10-17T09:20:30.547328Z",
          "iopub.status.idle": "2025-10-17T09:20:35.770445Z",
          "shell.execute_reply.started": "2025-10-17T09:20:30.547314Z",
          "shell.execute_reply": "2025-10-17T09:20:35.769864Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Препроцессинг данных и создание словаря (1 балл)\n",
        "\n",
        "Далее вам необходмо самостоятельно произвести препроцессинг данных и получить словарь или же просто ```set``` строк. Что необходимо сделать:\n",
        "\n",
        "1. Разделить отдельные тренировочные примеры на отдельные предложения с помощью функции ```sent_tokenize``` из бибилиотеки ```nltk```. Каждое отдельное предложение будет одним тренировочным примером.\n",
        "2. Оставить только те предложения, в которых меньше ```word_threshold``` слов.\n",
        "3. Посчитать частоту вхождения каждого слова в оставшихся предложениях. Для деления предлоения на отдельные слова удобно использовать функцию ```word_tokenize```.\n",
        "4. Создать объект ```vocab``` класса ```set```, положить в него служебные токены '\\<unk\\>', '\\<bos\\>', '\\<eos\\>', '\\<pad\\>' и vocab_size самых частовстречающихся слов.   "
      ],
      "metadata": {
        "id": "24gn7CuZ9agP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "word_threshold = 32\n",
        "\n",
        "for features in dataset['train']:\n",
        "    sentences.extend(\n",
        "        [sentence for sentence in sent_tokenize(features['text']) if len(word_tokenize(sentence)) < word_threshold]\n",
        "    )"
      ],
      "metadata": {
        "id": "Ins2tVCdsS47",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:20:35.771351Z",
          "iopub.execute_input": "2025-10-17T09:20:35.771599Z",
          "iopub.status.idle": "2025-10-17T09:21:09.010849Z",
          "shell.execute_reply.started": "2025-10-17T09:20:35.771581Z",
          "shell.execute_reply": "2025-10-17T09:21:09.01023Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Всего предложений:\", len(sentences))"
      ],
      "metadata": {
        "id": "bxeBxP3J1Rj3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:09.018023Z",
          "iopub.execute_input": "2025-10-17T09:21:09.018271Z",
          "iopub.status.idle": "2025-10-17T09:21:10.148261Z",
          "shell.execute_reply.started": "2025-10-17T09:21:09.018254Z",
          "shell.execute_reply": "2025-10-17T09:21:10.147541Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем для каждого слова его встречаемость."
      ],
      "metadata": {
        "id": "iT82XkT6ULA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = Counter()\n",
        "\n",
        "for sentence in sentences:\n",
        "    words.update(word_tokenize(sentence))"
      ],
      "metadata": {
        "id": "nEvCN0Y1w1yH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:10.149012Z",
          "iopub.execute_input": "2025-10-17T09:21:10.149239Z",
          "iopub.status.idle": "2025-10-17T09:21:25.923846Z",
          "shell.execute_reply.started": "2025-10-17T09:21:10.149214Z",
          "shell.execute_reply": "2025-10-17T09:21:25.923245Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим в словарь ```vocab_size``` самых встречающихся слов."
      ],
      "metadata": {
        "id": "B4k4uSoHUSI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "vocab_size = 40000\n",
        "\n",
        "vocab.update(sorted(list(words.keys()), key=lambda word: words[word], reverse=True)[:vocab_size])\n",
        "\n",
        "vocab.update(['<unk>', '<bos>', '<eos>', '<pad>'])\n"
      ],
      "metadata": {
        "id": "oUBNwsK9xLIu",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:25.924581Z",
          "iopub.execute_input": "2025-10-17T09:21:25.924808Z",
          "iopub.status.idle": "2025-10-17T09:21:25.95239Z",
          "shell.execute_reply.started": "2025-10-17T09:21:25.924793Z",
          "shell.execute_reply": "2025-10-17T09:21:25.951738Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert '<unk>' in vocab\n",
        "assert '<bos>' in vocab\n",
        "assert '<eos>' in vocab\n",
        "assert '<pad>' in vocab\n",
        "assert len(vocab) == vocab_size + 4"
      ],
      "metadata": {
        "id": "ieT0DFUpXnV2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:25.953215Z",
          "iopub.execute_input": "2025-10-17T09:21:25.95393Z",
          "iopub.status.idle": "2025-10-17T09:21:25.962483Z",
          "shell.execute_reply.started": "2025-10-17T09:21:25.953905Z",
          "shell.execute_reply": "2025-10-17T09:21:25.961955Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Всего слов в словаре:\", len(vocab))"
      ],
      "metadata": {
        "id": "JhACW2CQyck5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:25.96314Z",
          "iopub.execute_input": "2025-10-17T09:21:25.96332Z",
          "iopub.status.idle": "2025-10-17T09:21:25.976125Z",
          "shell.execute_reply.started": "2025-10-17T09:21:25.963305Z",
          "shell.execute_reply": "2025-10-17T09:21:25.975542Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка датасета (1 балл)\n",
        "\n",
        "Далее, как и в семинарском занятии, подготовим датасеты и даталоадеры.\n",
        "\n",
        "В классе ```WordDataset``` вам необходимо реализовать метод ```__getitem__```, который будет возвращать сэмпл данных по входному idx, то есть список целых чисел (индексов слов).\n",
        "\n",
        "Внутри этого метода необходимо добавить служебные токены начала и конца последовательности, а также токенизировать соответствующее предложение с помощью ```word_tokenize``` и сопоставить ему индексы из ```word2ind```."
      ],
      "metadata": {
        "id": "UmeRYKSIUcdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2ind = {char: i for i, char in enumerate(vocab)}\n",
        "ind2word = {i: char for char, i in word2ind.items()}"
      ],
      "metadata": {
        "id": "iD7SmSy3v2dl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:25.976733Z",
          "iopub.execute_input": "2025-10-17T09:21:25.976944Z",
          "iopub.status.idle": "2025-10-17T09:21:25.997169Z",
          "shell.execute_reply.started": "2025-10-17T09:21:25.976921Z",
          "shell.execute_reply": "2025-10-17T09:21:25.996436Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class WordDataset(Dataset):\n",
        "    def __init__(self, sentences):\n",
        "        self.unk_id = word2ind['<unk>']\n",
        "        self.bos_id = word2ind['<bos>']\n",
        "        self.eos_id = word2ind['<eos>']\n",
        "        self.pad_id = word2ind['<pad>']\n",
        "\n",
        "        self.tokenized_data = []\n",
        "        for sentence in sentences:\n",
        "            words_in_sent = word_tokenize(sentence)\n",
        "            ids = [word2ind.get(w, self.unk_id) for w in words_in_sent]\n",
        "            tokenized_sentence = [self.bos_id] + ids + [self.eos_id]\n",
        "            self.tokenized_data.append(tokenized_sentence)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> List[int]:\n",
        "        return self.tokenized_data[idx]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tokenized_data)\n"
      ],
      "metadata": {
        "id": "FVzXL17PzC7K",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:25.999536Z",
          "iopub.execute_input": "2025-10-17T09:21:25.999751Z",
          "iopub.status.idle": "2025-10-17T09:21:26.009014Z",
          "shell.execute_reply.started": "2025-10-17T09:21:25.999737Z",
          "shell.execute_reply": "2025-10-17T09:21:26.008317Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_with_padding(\n",
        "    input_batch: List[List[int]], pad_id=word2ind['<pad>']) -> torch.Tensor:\n",
        "    seq_lens = [len(x) for x in input_batch]\n",
        "    max_seq_len = max(seq_lens)\n",
        "\n",
        "    new_batch = []\n",
        "    for sequence in input_batch:\n",
        "        for _ in range(max_seq_len - len(sequence)):\n",
        "            sequence.append(pad_id)\n",
        "        new_batch.append(sequence)\n",
        "\n",
        "    sequences = torch.LongTensor(new_batch).to(device)\n",
        "\n",
        "    new_batch = {\n",
        "        'input_ids': sequences[:,:-1],\n",
        "        'target_ids': sequences[:,1:]\n",
        "    }\n",
        "\n",
        "    return new_batch"
      ],
      "metadata": {
        "id": "I6CtYNMp2_g0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:26.009768Z",
          "iopub.execute_input": "2025-10-17T09:21:26.010012Z",
          "iopub.status.idle": "2025-10-17T09:21:26.02292Z",
          "shell.execute_reply.started": "2025-10-17T09:21:26.009992Z",
          "shell.execute_reply": "2025-10-17T09:21:26.022349Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, eval_sentences = train_test_split(sentences, test_size=0.2)\n",
        "eval_sentences, test_sentences = train_test_split(sentences, test_size=0.5)\n",
        "\n",
        "train_dataset = WordDataset(train_sentences)\n",
        "eval_dataset = WordDataset(eval_sentences)\n",
        "test_dataset = WordDataset(test_sentences)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, collate_fn=collate_fn_with_padding, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "6xmeK9Ys1BIG",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:26.023745Z",
          "iopub.execute_input": "2025-10-17T09:21:26.024175Z",
          "iopub.status.idle": "2025-10-17T09:21:55.404799Z",
          "shell.execute_reply.started": "2025-10-17T09:21:26.02416Z",
          "shell.execute_reply": "2025-10-17T09:21:55.403948Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение и архитектура модели\n",
        "\n",
        "Вам необходимо на практике проверить, что влияет на качество языковых моделей. В этом задании нужно провести серию экспериментов с различными вариантами языковых моделей и сравнить различия в конечной перплексии на тестовом множестве.\n",
        "\n",
        "Возмоэные идеи для экспериментов:\n",
        "\n",
        "* Различные RNN-блоки, например, LSTM или GRU. Также можно добавить сразу несколько RNN блоков друг над другом с помощью аргумента num_layers. Вам поможет официальная документация [здесь](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
        "* Различные размеры скрытого состояния. Различное количество линейных слоев после RNN-блока. Различные функции активации.\n",
        "* Добавление нормализаций в виде Dropout, BatchNorm или LayerNorm\n",
        "* Различные аргументы для оптимизации, например, подбор оптимального learning rate или тип алгоритма оптимизации SGD, Adam, RMSProp и другие\n",
        "* Любые другие идеи и подходы\n",
        "\n",
        "После проведения экспериментов необходимо составить таблицу результатов, в которой описан каждый эксперимент и посчитана перплексия на тестовом множестве.\n",
        "\n",
        "Учтите, что эксперименты, которые различаются, например, только размером скрытого состояния или количеством линейных слоев считаются, как один эксперимент.\n",
        "\n",
        "Успехов!"
      ],
      "metadata": {
        "id": "SMAexY7Y45E4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функция evaluate (1 балл)\n",
        "\n",
        "Заполните функцию ```evaluate```"
      ],
      "metadata": {
        "id": "KP1cO-3bmDv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, criterion, dataloader) -> float:\n",
        "    model.eval()\n",
        "    perplexity = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            logits = model(batch['input_ids']).flatten(0, 1)\n",
        "            loss = criterion(logits, batch['target_ids'].flatten())\n",
        "            perplexity.append(torch.exp(loss).item())\n",
        "\n",
        "    perplexity = sum(perplexity) / len(perplexity)\n",
        "\n",
        "    return perplexity"
      ],
      "metadata": {
        "id": "XUlMUVJ3mL4r",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:55.405692Z",
          "iopub.execute_input": "2025-10-17T09:21:55.406031Z",
          "iopub.status.idle": "2025-10-17T09:21:55.411372Z",
          "shell.execute_reply.started": "2025-10-17T09:21:55.405965Z",
          "shell.execute_reply": "2025-10-17T09:21:55.41052Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train loop (1 балл)\n",
        "\n",
        "Напишите функцию для обучения модели."
      ],
      "metadata": {
        "id": "bLV63Vsk7loy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_loop(model, optimizer, criterion, train_dataloader, eval_dataloader,\n",
        "               device, n_epochs, patience=3):\n",
        "\n",
        "    history = {'train_loss': [], 'val_perplexity': []}\n",
        "    best_perplexity = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = []\n",
        "\n",
        "        for batch in tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{n_epochs} [Training]'):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits = model(batch['input_ids']).flatten(0, 1)\n",
        "            loss = criterion(logits, batch['target_ids'].flatten())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "        avg_train_loss = sum(epoch_loss) / len(epoch_loss)\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "\n",
        "        val_perplexity = evaluate(model, criterion, eval_dataloader)\n",
        "        history['val_perplexity'].append(val_perplexity)\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        plt.figure(figsize=(14, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history['train_loss'], label='Train Loss')\n",
        "        plt.title('Training Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history['val_perplexity'], label='Validation Perplexity')\n",
        "        plt.title('Validation Perplexity')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {avg_train_loss:.4f}, Val Perplexity: {val_perplexity:.4f}\")\n",
        "\n",
        "        if val_perplexity < best_perplexity:\n",
        "            best_perplexity = val_perplexity\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {patience} epochs with no improvement.\")\n",
        "            break\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "b9HqewEnXrKb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:55.412113Z",
          "iopub.execute_input": "2025-10-17T09:21:55.41232Z",
          "iopub.status.idle": "2025-10-17T09:21:55.431467Z",
          "shell.execute_reply.started": "2025-10-17T09:21:55.412297Z",
          "shell.execute_reply": "2025-10-17T09:21:55.430758Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Первый эксперимент (2 балла)\n",
        "\n",
        "Определите архитектуру модели и обучите её."
      ],
      "metadata": {
        "id": "hXmeyhBQmuq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "                 dropout_p=0.2, rnn_type='LSTM'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim,\n",
        "                                      padding_idx=word2ind['<pad>'])\n",
        "\n",
        "        if rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers,\n",
        "                               batch_first=True, dropout=dropout_p if num_layers > 1 else 0)\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers,\n",
        "                              batch_first=True, dropout=dropout_p if num_layers > 1 else 0)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers,\n",
        "                              batch_first=True, dropout=dropout_p if num_layers > 1 else 0)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        rnn_out, _ = self.rnn(embedded)\n",
        "\n",
        "        logits = self.fc(rnn_out)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "qaWvqNJom0ij",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:55.432354Z",
          "iopub.execute_input": "2025-10-17T09:21:55.432682Z",
          "iopub.status.idle": "2025-10-17T09:21:55.447325Z",
          "shell.execute_reply.started": "2025-10-17T09:21:55.432659Z",
          "shell.execute_reply": "2025-10-17T09:21:55.446808Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q optuna"
      ],
      "metadata": {
        "id": "e3R5gT2TX_lA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:55.448282Z",
          "iopub.execute_input": "2025-10-17T09:21:55.448526Z",
          "iopub.status.idle": "2025-10-17T09:21:58.58869Z",
          "shell.execute_reply.started": "2025-10-17T09:21:55.448482Z",
          "shell.execute_reply": "2025-10-17T09:21:58.587832Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    rnn_type = trial.suggest_categorical('rnn_type', ['LSTM', 'GRU'])\n",
        "    embedding_dim = trial.suggest_categorical('embedding_dim', [128, 256])\n",
        "    hidden_dim = trial.suggest_categorical('hidden_dim', [256, 512])\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 2)\n",
        "    dropout_p = trial.suggest_float('dropout_p', 0.0, 0.3)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-2, log=True)\n",
        "\n",
        "    model = LanguageModel(\n",
        "        vocab_size=len(vocab),\n",
        "        embedding_dim=embedding_dim,\n",
        "        hidden_dim=hidden_dim,\n",
        "        num_layers=num_layers,\n",
        "        dropout_p=dropout_p,\n",
        "        rnn_type=rnn_type\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=word2ind['<pad>'])\n",
        "\n",
        "    N_EPOCHS_TRIAL = 5\n",
        "\n",
        "    for epoch in range(N_EPOCHS_TRIAL):\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(batch['input_ids']).flatten(0, 1)\n",
        "            loss = criterion(logits, batch['target_ids'].flatten())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        val_perplexity = evaluate(model, criterion, eval_dataloader)\n",
        "\n",
        "        trial.report(val_perplexity, epoch)\n",
        "\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return val_perplexity"
      ],
      "metadata": {
        "id": "WPGr1YDmYCjD",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:58.589923Z",
          "iopub.execute_input": "2025-10-17T09:21:58.590194Z",
          "iopub.status.idle": "2025-10-17T09:21:58.813167Z",
          "shell.execute_reply.started": "2025-10-17T09:21:58.590171Z",
          "shell.execute_reply": "2025-10-17T09:21:58.812411Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
        "\n",
        "study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value (Perplexity): {trial.value}\")\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ],
      "metadata": {
        "id": "jT_OQ_7vYo1X",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T09:21:58.813928Z",
          "iopub.execute_input": "2025-10-17T09:21:58.814123Z",
          "iopub.status.idle": "2025-10-17T14:24:45.853701Z",
          "shell.execute_reply.started": "2025-10-17T09:21:58.814108Z",
          "shell.execute_reply": "2025-10-17T14:24:45.852829Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params\n",
        "\n",
        "final_model = LanguageModel(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=best_params['embedding_dim'],\n",
        "    hidden_dim=best_params['hidden_dim'],\n",
        "    num_layers=best_params['num_layers'],\n",
        "    dropout_p=best_params['dropout_p'],\n",
        "    rnn_type=best_params['rnn_type']\n",
        ").to(device)\n",
        "\n",
        "final_optimizer = torch.optim.AdamW(\n",
        "    final_model.parameters(), lr=best_params['learning_rate'])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word2ind['<pad>'])\n",
        "\n",
        "train_loop(final_model, final_optimizer, criterion, train_dataloader,\n",
        "           eval_dataloader, device, n_epochs=20, patience=5)\n",
        "\n",
        "\n",
        "test_perplexity = evaluate(final_model, criterion, test_dataloader)\n",
        "print(f'Итоговая перплексия на тестовом наборе: {test_perplexity:.4f}')"
      ],
      "metadata": {
        "id": "CEJRVDZRJBeJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T14:26:38.973917Z",
          "iopub.execute_input": "2025-10-17T14:26:38.974232Z",
          "iopub.status.idle": "2025-10-17T16:05:27.309461Z",
          "shell.execute_reply.started": "2025-10-17T14:26:38.974213Z",
          "shell.execute_reply": "2025-10-17T16:05:27.308569Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def generate_sequence(model, starting_seq: str, max_len: int = 50, temperature: float = 0.8):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    tokenized_start = word_tokenize(starting_seq.lower())\n",
        "    input_ids = [word2ind['<bos>']] + [\n",
        "        word2ind.get(word, word2ind['<unk>']) for word in tokenized_start\n",
        "    ]\n",
        "\n",
        "    input_tensor = torch.LongTensor([input_ids]).to(device)\n",
        "\n",
        "    generated_indices = list(input_ids)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            logits = model(input_tensor)\n",
        "\n",
        "            last_word_logits = logits[:, -1, :]\n",
        "\n",
        "            if temperature > 0:\n",
        "                probabilities = F.softmax(last_word_logits / temperature, dim=-1)\n",
        "                next_token_id = torch.multinomial(probabilities, num_samples=1).item()\n",
        "            else:\n",
        "                next_token_id = torch.argmax(last_word_logits, dim=-1).item()\n",
        "\n",
        "            if next_token_id == word2ind['<eos>']:\n",
        "                break\n",
        "\n",
        "            generated_indices.append(next_token_id)\n",
        "\n",
        "            input_tensor = torch.LongTensor([generated_indices]).to(device)\n",
        "\n",
        "    generated_words = [ind2word.get(idx, '<unk>') for idx in generated_indices]\n",
        "\n",
        "    final_sequence = ' '.join(word for word in generated_words if word not in ['<bos>', '<eos>'])\n",
        "\n",
        "    return final_sequence"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T16:10:11.085831Z",
          "iopub.execute_input": "2025-10-17T16:10:11.086578Z",
          "iopub.status.idle": "2025-10-17T16:10:11.093241Z",
          "shell.execute_reply.started": "2025-10-17T16:10:11.086549Z",
          "shell.execute_reply": "2025-10-17T16:10:11.092623Z"
        },
        "id": "Wo-hHAmIUe2p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.eval()\n",
        "\n",
        "prompt = \"this movie was about\"\n",
        "print(\"--- Greedy Search (temperature=0.0) ---\")\n",
        "print(generate_sequence(final_model, starting_seq=prompt, max_len=30, temperature=0.0))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"--- Sampling (temperature=0.5) ---\")\n",
        "print(generate_sequence(final_model, starting_seq=prompt, max_len=30, temperature=0.5))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T16:12:14.863942Z",
          "iopub.execute_input": "2025-10-17T16:12:14.864639Z",
          "iopub.status.idle": "2025-10-17T16:12:14.911887Z",
          "shell.execute_reply.started": "2025-10-17T16:12:14.864615Z",
          "shell.execute_reply": "2025-10-17T16:12:14.911294Z"
        },
        "id": "cc061bgEUe2p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Второй эксперимент (2 балла)\n",
        "\n",
        "Попробуйте что-то поменять в модели или в пайплайне обучения, идеи для экспериментов можно подсмотреть выше."
      ],
      "metadata": {
        "id": "X1EW4faIm0tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# эксперименты провелись внутри optuna (см. выше)"
      ],
      "metadata": {
        "id": "wkSE4jR1XzTg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-17T14:24:46.124009Z",
          "iopub.status.idle": "2025-10-17T14:24:46.124337Z",
          "shell.execute_reply.started": "2025-10-17T14:24:46.124204Z",
          "shell.execute_reply": "2025-10-17T14:24:46.124219Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Отчет (2 балла)\n",
        "\n",
        "Опишите проведенные эксперименты. Сравните перплексии полученных моделей. Предложите идеи по улучшению качества моделей."
      ],
      "metadata": {
        "id": "Y5V9H3eoFeAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я организовал автоматические эксперименты с помощью библиотеки Optuna. От эксперимента к эксперименту варьировались:\n",
        "1. Тип модели: GRU / LSTM\n",
        "2. Количество слоев: 1 / 2\n",
        "3. Размер эмбеддингов: 128 / 256\n",
        "4. Размер hidden_dim: 256 / 512\n",
        "5. Вероятность (процент) дропаута нейронов: 0.0-0.3\n",
        "6. Величина шага обучения: 0.001-0.01\n",
        "\n",
        "Анализ показал, что наибольшее влияние на метрику (перплексию) в указанных диапазонах оказывают количество слоев (1 лучше 2), а также дропаут (чем меньше, тем лучше). Думаю, стоит провести дополнительное исследование сравнивающее две модели GRU и LSTM, займусь этим когда дойдут руки :)"
      ],
      "metadata": {
        "id": "OcW7cu7EUe25"
      }
    }
  ]
}